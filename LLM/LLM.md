# 基座模型
## LLaMA
[LLaMA: Open and Efficient Foundation Language Models](http://arxiv.org/abs/2302.13971)
- 使用PreNorm的RMS Norm，说作用是归一化的时候不改变词向量的方向，其实看公式能很直观的理解，去掉了减去均值的部分
- 在MLP中增加一层门控

## A Comprehensive Survey of Continual Learning:Theory, Method and Application(http://arxiv.org/abs/2302.13971))
- 综述文章，介绍了CL（Continual Learning)
